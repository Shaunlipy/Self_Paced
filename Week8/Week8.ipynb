{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8\n",
    "weekly practice from The Math of Intelligence by Siraj Raval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To save hidden layer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data - binary numbers for each interger from 0 to 256\n",
    "int_to_binary = {}\n",
    "binary_dim = 8\n",
    "max_val = 2**binary_dim # = 256\n",
    "binary_val = np.unpackbits(np.array([range(max_val)], dtype = np.uint8).T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " ..., \n",
      " [1 1 1 ..., 1 0 1]\n",
      " [1 1 1 ..., 1 1 0]\n",
      " [1 1 1 ..., 1 1 1]]\n",
      "256\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(binary_val)\n",
    "print (len(binary_val))\n",
    "print (len(binary_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(max_val):\n",
    "    int_to_binary[i] = binary_val[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (int_to_binary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def activate(x, deriv = False):\n",
    "    if(deriv == True):\n",
    "        return x*(1 - x)\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "inputLayerSize = 2\n",
    "hiddenLayerSize = 16\n",
    "outputLayerSize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 Weight Values\n",
    "w1 = 2 * np.random.random((inputLayerSize, hiddenLayerSize)) - 1\n",
    "w2 = 2 * np.random.random((hiddenLayerSize, outputLayerSize)) - 1\n",
    "# From current hidden to next hidden\n",
    "w_h = 2 * np.random.random((hiddenLayerSize, hiddenLayerSize)) - 1\n",
    "\n",
    "# Initialize updated weights values\n",
    "w1_update = np.zeros_like(w1)\n",
    "w2_update = np.zeros_like(w2)\n",
    "w_h_update = np.zeros_like(w_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[ 4.02439138]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "20 + 69 = 255\n",
      "------------\n",
      "Error:[ 0.44111426]\n",
      "Pred:[1 0 0 1 1 1 0 0]\n",
      "True:[1 0 0 1 1 1 0 0]\n",
      "117 + 39 = 156\n",
      "------------\n",
      "Error:[ 0.24655136]\n",
      "Pred:[1 0 1 0 1 0 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "126 + 45 = 171\n",
      "------------\n",
      "Error:[ 0.10152159]\n",
      "Pred:[0 1 0 1 1 0 0 0]\n",
      "True:[0 1 0 1 1 0 0 0]\n",
      "21 + 67 = 88\n",
      "------------\n",
      "Error:[ 0.14344125]\n",
      "Pred:[0 1 0 1 1 0 0 0]\n",
      "True:[0 1 0 1 1 0 0 0]\n",
      "29 + 59 = 88\n",
      "------------\n",
      "Error:[ 0.07757354]\n",
      "Pred:[0 0 1 1 0 0 0 0]\n",
      "True:[0 0 1 1 0 0 0 0]\n",
      "35 + 13 = 48\n",
      "------------\n",
      "Error:[ 0.07424355]\n",
      "Pred:[1 0 1 0 0 1 0 0]\n",
      "True:[1 0 1 0 0 1 0 0]\n",
      "48 + 116 = 164\n",
      "------------\n",
      "Error:[ 1.82523196]\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 1 0 0 1 1]\n",
      "110 + 5 = 99\n",
      "------------\n",
      "Error:[ 1.15409802]\n",
      "Pred:[0 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "120 + 49 = 41\n",
      "------------\n",
      "Error:[ 0.03784354]\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "88 + 36 = 124\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Compute the sum of two integers\n",
    "for j in range(10000):\n",
    "    # a + b = c (random values)\n",
    "    a_int = np.random.randint(max_val / 2)\n",
    "    b_int = np.random.randint(max_val / 2)\n",
    "    c_int = a_int + b_int\n",
    "    \n",
    "    # Get binary values for a, b, c\n",
    "    a = int_to_binary[a_int]\n",
    "    b = int_to_binary[b_int]\n",
    "    c = int_to_binary[c_int]\n",
    "    \n",
    "    # Save predicted binary outputs\n",
    "    d = np.zeros_like(c)\n",
    "    \n",
    "    # Initialize Error\n",
    "    overallError = 0\n",
    "    \n",
    "    # Store output gradients & hidden layer values\n",
    "    output_layer_gradients = list()\n",
    "    hidden_layer_values = list()\n",
    "    hidden_layer_values.append(np.zeros(hiddenLayerSize)) \n",
    "    \n",
    "    for position in range(binary_dim):\n",
    "        # Input - binary values of a & b\n",
    "        X = np.array([[a[binary_dim - position - 1], b[binary_dim - position - 1]]])\n",
    "        # Output - the sum c\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T\n",
    "        \n",
    "        # Calculate the error\n",
    "        layer_1 = activate(np.dot(X, w1) + np.dot(hidden_layer_values[-1], w_h))\n",
    "        layer_2 = activate(np.dot(layer_1, w2))\n",
    "        output_error = y - layer_2\n",
    "        \n",
    "        # Save the error gradients at each step as it will be propagated back\n",
    "        output_layer_gradients.append((output_error) * activate(layer_2, deriv = True))\n",
    "        \n",
    "        # Save the sum of error at each binary position\n",
    "        overallError += np.abs(output_error[0])\n",
    "        \n",
    "        # Round \n",
    "        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n",
    "        \n",
    "        # Save the hidden layer\n",
    "        hidden_layer_values.append(copy.deepcopy(layer_1))\n",
    "        \n",
    "    future_layer_1_gradient = np.zeros(hiddenLayerSize)\n",
    "    \n",
    "    # Backpropagate\n",
    "    for position in range(binary_dim):\n",
    "        X = np.array([[a[position], b[position]]])\n",
    "        # The last step hidden layer\n",
    "        layer_1 = hidden_layer_values[-position - 1]\n",
    "        # The hidden layer before the current layer\n",
    "        prev_hidden_layer = hidden_layer_values[-position - 2]\n",
    "        # Errors at output layer\n",
    "        output_layer_gradient = output_layer_gradients[-position - 1]\n",
    "        layer_1_gradient = (future_layer_1_gradient.dot(w_h.T) + output_layer_gradient.dot(w2.T)) * activate(layer_1, deriv=True)\n",
    "        \n",
    "        # Update weights\n",
    "        w2_update += np.atleast_2d(layer_1).T.dot(output_layer_gradient)\n",
    "        w_h_update += np.atleast_2d(prev_hidden_layer).T.dot(layer_1_gradient)\n",
    "        w1_update += X.T.dot(layer_1_gradient)\n",
    "\n",
    "        future_layer_1_gradient = layer_1_gradient\n",
    "        \n",
    "    # Update the weights\n",
    "    w1 += w1_update\n",
    "    w2 += w2_update\n",
    "    w_h += w_h_update\n",
    "    \n",
    "    # Clear the updated weights values\n",
    "    w1_update *= 0\n",
    "    w2_update *= 0\n",
    "    w_h_update *= 0\n",
    "    \n",
    "    # Print out the Progress of the RNN\n",
    "    if (j % 1000 == 0):\n",
    "        print(\"Error:\" + str(overallError))\n",
    "        print(\"Pred:\" + str(d))\n",
    "        print(\"True:\" + str(c))\n",
    "        out = 0\n",
    "        for index, x in enumerate(reversed(d)):\n",
    "            out += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
    "        print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
